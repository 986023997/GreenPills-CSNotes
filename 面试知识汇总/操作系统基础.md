# 操作系统基础

## 1.并发与并行

- 并发是指宏观上在一段时间内能同时运行多个程序
- 并行则指同一时刻能运行多个指令

并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。操作系统通过引入进程和线程，使得程序能够并发运行。

## 2.死锁的条件及解决的办法

- 死锁的条件
    必须同时存在以下的四个条件才能发生死锁。

    1. 互斥条件
    即某个资源在一段时间内只能由一个进程占有，不能同时被两个或两个以上的进程占有。这种独占资源如CD-ROM驱动器，打印机等等，必须在占有该资源的进程主动释放它之后，其它进程才能占有该资源。这是由资源本身的属性所决定的。
    1. 不可抢占条件。
    进程所获得的资源在未使用完毕之前，资源申请者不能强行地从资源占有者手中夺取资源，而只能由该资源的占有者进程自行释放。
    1. 占有且申请条件。
    进程至少已经占有一个资源，但又申请新的资源；由于该资源已被另外进程占有，此时该进程阻塞；但是，它在等待新资源之时，仍继续占用已占有的资源。
    1. 循环等待条件
    存在一个进程等待序列{P1，P2，...，Pn}，其中P1等待P2所占有的某一资源，P2等待P3所占有的某一源，......，而Pn等待P1所占有的的某一资源，形成一个进程循环等待环。

- 死锁的预防
死锁的预防是保证系统不进入死锁状态的一种策略。

1. 破坏互斥条件
    有些资源不能被共享。--没用
    2. 破坏不可抢占条件。
    可抢占式，即要求申请失败的进程释放自己占有的资源给别人用，降低系统性能。
    3. 破坏占有且申请条件。
    直接申请自己所需要的所有资源。--1.不可预知自己需要什么资源  2.资源利用率低，长期占有自己可能不用的资源。
    4. 破坏循环等待条件
    资源分类、编号，按序申请。 --·1.编号可能是困难的，维护相应的序列是困难的

- 死锁的避免
死锁的避免指的是不限制进程有关申请资源的命令，而是对进程所发出的每一个申请资源命令加以动态地检查，并根据检查结果决定是否进行资源分配。
银行家算法。当一个进程申请使用资源的时候，银行家算法通过先 试探 分配给该进程资源，然后通过安全性算法判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待。

判定安全状态需要已分配资源、还需要的资源、可用资源、finish判定符。

## 3.进程和线程在

面向进程设计的系统（如早期的UNIX，Linux 2.4及更早的版本）中，进程是程序的基本执行实体；在面向线程设计的系统（如当代多数操作系统、Linux 2.6及更新的版本）中，进程本身不是基本运行单位，而是线程的容器。

### 3.1 进程

#### 3.1.1 概念

进程指的是在计算机中已经运行的程序。程序本身只是指令、数据和其组织形式的描述进程才是真正的运行实例。

#### 3.1.2 内容

1. 该程序的可执行机器码的在内存的拷贝。
2. 分配到的内存空间，内存中包括可执行代码，调用堆栈、堆栈等
3. 分配给该进程的操作系统描述符
4. 安全特征，如进程拥有则和进程的权限集
5. 处理器状态，寄存器、物理存储器地址

#### 3.1.3 状态

1. 新生（new）：进程新产生中。
2. 运行（running）：正在运行。
3. 等待（waiting）：等待某事发生，例如等待用户输入完成。亦称“阻塞”（blocked）
4. 就绪（ready）：排班中，等待CPU。
5. 结束（terminated）：完成运行。

#### 3.1.4 进程间私有和共享的资源

- 私有：地址空间、堆、全局变量、栈、寄存器
- 共享：代码段，公共数据，进程目录，进程 ID

#### 3.1.5 进程间通信(IPC)

1. 管道(PIPE)：一系列将标准输入输出链接起来的过程，其中每一个进程的输出被直接作为下一个进程的输入。
   - 无名管道
    使用C在UNIX中使用pipe()系统调用，会构建一个匿名管道，这样在进程中就打开了两个新的，打开的文件描述符：一个只读端一个只写端。管道的两端是两个普通的，匿名的文件描述符。一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程）。
        - 优点
          - 简单方便
        - 缺点
            1. 局限于单向通信
            2. 只能创建在它的进程以及其有亲缘关系的进程之间
            3. 缓冲区有限
   - 有名管道
    通过调用mkfifo()或mknod()来构建，当被调用时表现为输入或输出的文件。命名管道是一个设备文件，因此，即使进程与创建有名管道的进程不存在亲缘关系，只要可以访问该路径，就能够通过有名管道相互通信。一种半双工的通信方式，它允许无亲缘关系进程间的通信。
      - 优点：可以实现任意关系的进程间的通信
      - 缺点：
        1. 长期存于系统中，使用不当容易出错
        2. 缓冲区有限
2. 信号量(Semaphore)
    又称为信号标，是一个同步对象，用于保持在0至指定最大值之间的一个计数值。当线程完成一次对该semaphore对象的等待（wait）时，该计数值减一；当线程完成一次对semaphore对象的释放（release）时，计数值加一。当计数值为0，则线程等待该semaphore对象不再能成功直至该semaphore对象变成signaled状态。semaphore对象的计数值大于0，为signaled状态；计数值等于0，为nonsignaled状态.semaphore对象适用于控制一个仅支持有限个用户的共享资源，是一种不需要使用忙碌等待（busy waiting）的方法。

3. 信号(Signal)
   信号是一种异步的通知机制，用来提醒进程一个事件已经发生。当一个信号发送给一个进程，操作系统中断了进程正常的控制流程，此时，任何非原子操作都将被中断。如果进程定义了信号的处理函数，那么它将被执行，否则就执行默认的处理函数。

    通过控制终端发送的CTRL-C、CTRL-Z、CTRL-以及函数kill()等都会发送信号。
4. 消息队列(Message Queue)
   消息队列（英语：Message queue）是一种进程间通信或同一进程的不同线程间的通信方式，消息队列提供了异步的通信协议，每一个队列中的纪录包含详细说明的数据，包含发生的时间，输入设备的种类，以及特定的输入参数。
    特点：
   - 消息队列本身是异步的，它允许接收者在消息发送很长时间后再取回消息。
   - 接收者必须轮询消息队列，才能收到最近的消息
   - 信息的复制需要额外消耗 CPU 的时间
5. 内存共享
   映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问
    - 优点：无须复制，快捷，信息量大
    - 缺点：
      - 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题
      - 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信
6. 套接字
   在套接字接口中，以IP地址及通信端口组成套接字地址（socket address）。远程的套接字地址，以及本地的套接字地址完成连线后，再加上使用的协议（protocol），这个五元组（five-element tuple），作为套接字对（socket pairs），之后就可以彼此交换数据。

### 3.2 线程

#### 3.2.2 概念

线程是操作系统能进行运算调度的最小单位，他被包含在进程之中，是进程中的实际运作单元。一条线程指的是进程中一个但依顺序的控制流。一个进程中可以并发多个线程，每条线程并行执行不同的任务。线程是独立调度和分派的基本单位。同一进程中的多条线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等，但同一进程中的多个进程有各自的调用栈，自己第寄存器环境，自己的线程本地存储。一个进程可以有很多线程，每条线程并行执行不同的任务。

#### 3.2.2 优势

再多核或多CPU上使用多线程好处是提高了程序的执行吞吐率。在单CPU单核上，使用多线程也可以吧进程中负责I/O处理，人机交互而经常被阻塞的部分与秘籍计算的部分分开执行。

#### 3.2.3 状态

- 新建/派生/产生(NEW):刚创建的线程，并没有开始运行线程中的代码。-new函数
- 就绪状态(Runnable)：创建线程资源。-start()
- 运行状态(Running):获得CPU资源之后线程开始运行。-run()
- 阻塞状态(blocked):线程未结束，但出让CPU-被主动阻塞-sleep()  被I/O阻塞  等待锁
- 死亡状态(dead): 线程结束-正常退出结束 发生异常死亡

#### 3.2.4 线程间私有和共享的资源

- 私有：线程栈，寄存器，程序寄存器
- 共享：堆，地址空间，全局变量，静态变量

#### 3.2.5 线程间通信

1. 锁。包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）
    - 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。
    - 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。
    - 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁。
    - 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
2. 信号量
   见3.1.5信号量
3. 信号
   见3.1.5信号

### 3.3 进程和线程的异同

1. 进程是资源分配的最小单位，线程是程序执行的最小单位。

2. 进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。而线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。

3. 线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（IPC)进行。不过如何处理好同步与互斥是编写多线程程序的难点。

4. 但是多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。

## 4.操作系统的内存管理

### 4.1 虚拟内存

虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM）的使用也更有效率。

对虚拟内存的定义是基于对地址空间的重定义的，即把地址空间定义为“连续的虚拟内存地址”，以借此“欺骗”程序，使它们以为自己正在使用一大块的“连续”地址。 一个程序在运行时，我们会得到一个假象，该进程好像是独占地使用CPU和内存，CPU是没有间断地一条接一条的执行该程序的指令，所有的内存空间都是供该进程的代码和数据分配使用的。

CPU 通过一个虚拟地址（virtual address,VA）来访问主存，这个虚拟地址在被送到主存之前会先转换成一个物理地址。将虚拟地址转换成物理地址的任务叫做地址翻译（address translation）。

地址翻译需要 CPU 硬件和操作系统之间的配合。 CPU 芯片上叫做内存管理单元（Menory Management Unit, MMU）的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。

虚拟内存将主存看成是一个磁盘的高速缓存，主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据。

### 4.2 虚拟内存管理

#### 4.2.1 分页式存储管理

现代操作系统中虚拟内存和物理内存都是按照页进行管理，一个内存页是一段固定大小的连续内存地址的总称，在linux中，典型的内存页大小为诶4096Byte。因此内存地址也是通过页号和页内偏移进行表示的。

在64位，4G物理内存的机器中，虚拟地址的页号有52位，偏移是12位(2^12=4096,页内寻址需要12位)，物理内存的页号为20位，偏移量是12位(2^32=4G).

分页系统中，允许将进程的每一页离散地存储在内存的任一物理块中，为了能在内存中找到每个页面对应的物理块，系统为每个进程建立一张页表，用于记录进程逻辑页面与内存物理页面之间的对应关系。页表的作用是实现从页号到物理块号的地址映射，地址空间有多少页，该页表里就登记多少行，且按逻辑页的顺序排列。

#### 4.2.2 分段式存储管理

段是按照程序的自然分界划分的长度可以动态改变的区域。通常，程序员把子程序、操作数和常数等不同类型的数据划分到不同的段中，并且每个程序可以有多个相同类型的段。将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息。存储分配时，以段为单位，段与段在内存中可以不相邻接，也实现了离散分配。

在段式虚拟存储系统中，虚拟地址由段号和段内地址组成，每个表项至少包括三个字段：有效位（指明该段是否已经调入主存）、段起址(该段在实存中的首地址)和段长（记录该段的实际长度）

#### 4.2.3 段页式存储管理

段页式存储组织是分段式和分页式结合的存储组织方法，这样可充分利用分段管理和分页管理的优点。

1. 用分段方法来分配和管理虚拟存储器。程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页。
2. 用分页方法来分配和管理实存。即把整个主存分成与上述页大小相等的存储块，可装入作业的任何一页。程序对内存的调入或调出是按页进行的。但它又可按段实现共享和保护。

### 4.3 分页调度算法

1. 最佳调度算法

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。只是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

2. 最近最久未使用算法(LRU)

LRU算法是与每个页面最后使用的时间有关的。当必须置换一个页面时，LRU算法选择过去一段时间里最久未被使用的页面。

3. 最近未使用算法(NUR)

在存储分块表的每一表项中增加一个引用位，操作系统定期地将它们置为0。当某一页被访问时，由硬件将该位置1。过一段时间后，通过检查这些位可以确定哪些页使用过，哪些页自上次置0后还未使用过。就可把该位是0的页淘汰出去，因为在最近一段时间里它未被访问过。

4. 先进先出

最简单的页面置换算法是先入先出（FIFO）法。这种算法的实质是，总是选择在主存中停留时间最长（即最老）的一页置换，即先进入内存的页，先退出内存。理由是：最早调入内存的页，其不再被使用的可能性比刚调入内存的可能性大。建立一个FIFO队列，收容所有在内存中的页。被置换页面总是在队列头上进行。当一个页面被放入内存时，就把它插在队尾上。

5. 第二次机会算法

当选择置换页面时，检查它的访问位。如果是0，就淘汰这页；如果访问位是1，就给它第二次机会，并选择下一个FIFO页面。当一个页面得到第二次机会时，它的访问位就清为0，它的到达时间就置为当前时间。如果该页在此期间被访问过，则访问位置1。这样给了第二次机会的页面将不被淘汰，直至所有其他页面被淘汰过（或者也给了第二次机会）。因此，如果一个页面经常使用，它的访问位总保持为1，它就从来不会被淘汰出去。

### 4.4 可执行文件中的段在内存中的布局

![linuxMemory](https://pinkpills-1259674611.cos.ap-shanghai.myqcloud.com/webAssemblyAnalysis/memory-zh.png)

1. 代码段：代码段是用来存放可执行文件的操作指令，也就是说是它是可执行程序在内存中的镜像。代码段需要防止在运行时被非法修改，所以只准许读取操作，而不允许写入（修改）操作——它是不可写的。

2. 数据段：数据段用来存放可执行文件中已初始化全局变量，换句话说就是存放程序静态分配的变量和全局变量。

3. BSS段：BSS段包含了程序中未初始化的全局变量，在内存中 bss段全部置零。

4. 堆（heap）：堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减。当进程调用malloc等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）；当利用free等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减）

5. 栈：栈是用户存放程序临时创建的局部变量，也就是说我们函数括弧“{}”中定义的变量（但不包括static声明的变量，static意味着在数据段中存放变量）。除此以外，在函数被调用时，其参数也会被压入发起调用的进程栈中，并且待到调用结束后，函数的返回值也会被存放回栈中。由于栈的先进先出特点，所以栈特别方便用来保存/恢复调用现场。从这个意义上讲，我们可以把堆栈看成一个寄存、交换临时数据的内存区


## 5.Windows消息机制

## 6.虚拟内存是怎么实现的，要划分多少页，每页有多大？

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

## 7.线程锁

1. 互斥锁

    互斥锁用于控制多个线程对他们之间共享资源互斥访问的一个信号量。也就是说是为了避免多个线程在某一时刻同时操作一个共享资源。例如线程池中的有多个空闲线程和一个任务队列。任何是一个线程都要使用互斥锁互斥访问任务队列，以避免多个线程同时访问任务队列以发生错乱。

2. 条件锁

    条件锁就是所谓的条件变量，某一个线程因为某个条件为满足时可以使用条件变量使改程序处于阻塞状态。一旦条件满足以“信号量”的方式唤醒一个因为该条件而被阻塞的线程。最为常见就是在线程池中，起初没有任务时任务队列为空，此时线程池中的线程因为“任务队列为空”这个条件处于阻塞状态。一旦有任务进来，就会以信号量的方式唤醒一个线程来处理这个任务。这个过程中就使用到了条件变量pthread_cond_t。

3. 自旋锁
    自旋锁是一种busy-waiting的锁。也就是说，如果T1正在使用自旋锁，而T2也去申请这个自旋锁，此时T2肯定得不到这个自旋锁。与互斥锁相反的是，此时运行T2的处理器core2会一直不断地循环检查锁是否可用（自旋锁请求），直到获取到这个自旋锁为止。

4. 读写锁

    计算机中某些数据被多个进程共享，对数据库的操作有两种：一种是读操作，就是从数据库中读取数据不会修改数据库中内容；另一种就是写操作，写操作会修改数据库中存放的数据。因此可以得到我们允许在数据库上同时执行多个“读”操作，但是某一时刻只能在数据库上有一个“写”操作来更新数据。这就是一个简单的读者-写者模型。

## 8.进程调度算法

1. FCFS(First Come First Server，先来先服务)
    这是最简单，最基本的算法，它的思想非常简单，就是按照进程到来的时间顺序，逐个分配 CPU 资源
2. SJF(Short Job First，短作业优先)

    从后备队列中选择运行时间最短的进程进行服务。
    缺点：
    - 必须知道作业的运行时间，在采用这种算法时，要先知道每个作业运行时间。即使是程序员也很难估计作业的运行时间，如果估计过低，系统就可能按照估计的时间终止作业的运行，但此时作业并没有完成，故一般都会偏长估计。
    - 对长作业非常不利，长作业的周转时间会明显的增长。
    - 该调度算法完全未考虑作业的紧迫程度，故不能保证紧迫性作业能够得到及时处理。
3. PSA(优先级调度)
    按照进程的优先级选择调度顺序
4. RR (时间片轮转算法)
    为 CPU 的执行设定一个时间片大小，每个进程轮询分配时间片，时间片结束后暂停运行加入等待队列。
5. 多级反馈队列调度算法
    将时间片轮转与优先级调度相结合，把进程按优先级分成不同的队列，先按优先级调度，优先级相同的，按时间片轮转。优点是兼顾长短作业，有较好的响应时间，可行性强，适用于各种作业环境。
6. 高响应比优先调度算法
    根据“响应比=（进程执行时间+进程等待时间）/ 进程执行时间”这个公式得到的响应比来进行调度。高响应比优先算法在等待时间相同的情况下，作业执行的时间越短，响应比越高，满足段任务优先，同时响应比会随着等待时间增加而变大，优先级会提高，能够避免饥饿现象。优点是兼顾长短作业，缺点是计算响应比开销大，适用于批处理系统。
